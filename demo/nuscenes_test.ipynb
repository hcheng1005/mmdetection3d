{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.nuscenes import RadarPointCloud\n",
    "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
    "\n",
    "import operator\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from mayavi import mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "from transformers import AutoImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image,ImageDraw\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc = NuScenes(version='v1.0-mini', \n",
    "                dataroot='/home/zdhjs-05/myGitHubCode/v1.0-mini', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = nusc.scene[0] \n",
    "\n",
    "# 获取该场景的first token\n",
    "cur_sample_info = nusc.get('sample', scene['first_sample_token'])\n",
    "sensor_data_token = nusc.get('sample_data', cur_sample_info['data']['CAM_FRONT'])\n",
    "img_path_ = nusc.get_sample_data_path(cur_sample_info['data']['CAM_FRONT'])\n",
    "image = Image.open(img_path_)\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = image_processor.post_process_object_detection(outputs, threshold=0.4, target_sizes=target_sizes)[0]\n",
    "\n",
    "draw = ImageDraw.Draw(image)\n",
    "img = cv2.imread(img_path_)\n",
    "\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(box)\n",
    "    draw.rectangle(box, outline=\"#FF0000\", width=2)\n",
    "    \n",
    "    img = cv2.rectangle(img, (int(box[0]), int(box[1])),\n",
    "                             (int(box[2]),int(box[3])), (255, 0,0))\n",
    "cv2.imshow('xxx', img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "# image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
