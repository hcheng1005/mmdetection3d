{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.nuscenes import RadarPointCloud\n",
    "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
    "\n",
    "import operator\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from mayavi import mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "from transformers import AutoImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image,ImageDraw\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Database version not found: /home/charles/myDataSet/nuScenes/v1.0-mini/v1.0-mini",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68987/3601280348.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nusc = NuScenes(version='v1.0-mini', \n\u001b[0m\u001b[1;32m      2\u001b[0m                 dataroot='/home/charles/myDataSet/nuScenes/v1.0-mini', verbose=True)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nuscenes_devkit-1.1.9-py3.9.egg/nuscenes/nuscenes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, dataroot, verbose, map_resolution)\u001b[0m\n\u001b[1;32m     60\u001b[0m                             'ego_pose', 'log', 'scene', 'sample', 'sample_data', 'sample_annotation', 'map']\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Database version not found: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Database version not found: /home/charles/myDataSet/nuScenes/v1.0-mini/v1.0-mini"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version='v1.0-mini', \n",
    "                dataroot='/home/zdhjs-05/myGitHubCode/v1.0-mini', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = nusc.scene[0] \n",
    "\n",
    "# 获取该场景的first token\n",
    "cur_sample_info = nusc.get('sample', scene['first_sample_token'])\n",
    "sensor_data_token = nusc.get('sample_data', cur_sample_info['data']['CAM_FRONT'])\n",
    "img_path_ = nusc.get_sample_data_path(cur_sample_info['data']['CAM_FRONT'])\n",
    "image = Image.open(img_path_)\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = image_processor.post_process_object_detection(outputs, threshold=0.4, target_sizes=target_sizes)[0]\n",
    "\n",
    "draw = ImageDraw.Draw(image)\n",
    "img = cv2.imread(img_path_)\n",
    "\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(box)\n",
    "    draw.rectangle(box, outline=\"#FF0000\", width=2)\n",
    "    \n",
    "    img = cv2.rectangle(img, (int(box[0]), int(box[1])),\n",
    "                             (int(box[2]),int(box[3])), (255, 0,0))\n",
    "cv2.imshow('xxx', img)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "# image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
